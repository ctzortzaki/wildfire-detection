{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "iKQxRcXwFYqK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKQxRcXwFYqK",
        "outputId": "35402760-2a07-4291-d473-a983f08fa5f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/the_wildfire_dataset_2n_version'\n",
        "test_dir = '/content/drive/MyDrive/the_wildfire_dataset_2n_version1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9732fc11",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9732fc11",
        "outputId": "29972fb5-d519-4559-9c6c-16b57db5b455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, ConcatDataset, Subset\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import timm\n",
        "\n",
        "# # === Configuration ===\n",
        "# train_dir = '../Project/the_wildfire_dataset_2n_version/train/'\n",
        "# test_dir = '../Project/the_wildfire_dataset_2n_version/test/'\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "img_size = 224\n",
        "learning_rate = 1e-3\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# === Transforms ===\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "# === Dataset Loading ===\n",
        "train_data = datasets.ImageFolder(os.path.join(train_dir, \"train\"), transform=transform_train)\n",
        "test_data = datasets.ImageFolder(os.path.join(test_dir, \"test\"), transform=transform)\n",
        "val_data = datasets.ImageFolder(os.path.join(test_dir, \"val\"), transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "class_names = train_data.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "49e8d05f",
      "metadata": {
        "id": "49e8d05f"
      },
      "outputs": [],
      "source": [
        "def build_model_from_scratch():\n",
        "    model = models.resnet18(pretrained=False)\n",
        "    model.fc = nn.Linear(model.fc.in_features, len(class_names))\n",
        "    return model\n",
        "\n",
        "def build_finetuned_model():\n",
        "    model = models.resnet18(pretrained=True)  # Load pre-trained ResNet18\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False  # Freeze all layers except the final fully connected layer\n",
        "\n",
        "    model.fc = nn.Linear(model.fc.in_features, len(class_names))\n",
        "    return model\n",
        "\n",
        "def ViT_model():\n",
        "  model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "  model.head = nn.Linear(model.head.in_features, len(class_names))\n",
        "  model = model.to(device)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e9319fbe",
      "metadata": {
        "id": "e9319fbe"
      },
      "outputs": [],
      "source": [
        "# def train_model(model, train_loader, val_loader, epochs=10):\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct_train += (preds == labels).sum().item()\n",
        "            total_train += labels.size(0)\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        train_accuracy = correct_train / total_train\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct_val += (preds == labels).sum().item()\n",
        "                total_val += labels.size(0)\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        val_accuracy = correct_val / total_val\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "              f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f} | \"\n",
        "              f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4d6875a0",
      "metadata": {
        "id": "4d6875a0"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds = outputs.argmax(1).cpu().numpy()\n",
        "            y_pred.extend(preds)\n",
        "            y_true.extend(labels.numpy())\n",
        "\n",
        "    # Metrics\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "76b412f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76b412f4",
        "outputId": "6708354a-b443-4264-e6be-3631752d4c49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model from scratch...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (89747104 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (104688771 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.7176, Train Acc: 0.6520 | Val Loss: 0.6236, Val Acc: 0.7189\n",
            "Epoch 2/10 | Train Loss: 0.5625, Train Acc: 0.6970 | Val Loss: 0.6110, Val Acc: 0.7040\n",
            "Epoch 3/10 | Train Loss: 0.5769, Train Acc: 0.6954 | Val Loss: 0.5297, Val Acc: 0.7139\n",
            "Epoch 4/10 | Train Loss: 0.5326, Train Acc: 0.7230 | Val Loss: 0.5087, Val Acc: 0.7239\n",
            "Epoch 5/10 | Train Loss: 0.5265, Train Acc: 0.7320 | Val Loss: 0.5972, Val Acc: 0.7363\n",
            "Epoch 6/10 | Train Loss: 0.5019, Train Acc: 0.7542 | Val Loss: 0.5802, Val Acc: 0.6816\n",
            "Epoch 7/10 | Train Loss: 0.4872, Train Acc: 0.7643 | Val Loss: 0.5804, Val Acc: 0.6940\n",
            "Epoch 8/10 | Train Loss: 0.4805, Train Acc: 0.7744 | Val Loss: 0.4503, Val Acc: 0.7761\n",
            "Epoch 9/10 | Train Loss: 0.4716, Train Acc: 0.7733 | Val Loss: 0.4932, Val Acc: 0.7711\n",
            "Epoch 10/10 | Train Loss: 0.4668, Train Acc: 0.7823 | Val Loss: 0.5235, Val Acc: 0.7612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (96631920 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (94487082 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (101859328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fire       0.69      0.83      0.76       159\n",
            "      nofire       0.88      0.77      0.82       251\n",
            "\n",
            "    accuracy                           0.79       410\n",
            "   macro avg       0.79      0.80      0.79       410\n",
            "weighted avg       0.81      0.79      0.80       410\n",
            "\n",
            "Confusion Matrix:\n",
            "[[132  27]\n",
            " [ 58 193]]\n"
          ]
        }
      ],
      "source": [
        "# === Train from Scratch ===\n",
        "print(\"Training model from scratch...\")\n",
        "model = build_model_from_scratch().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)\n",
        "evaluate_model(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "66be23ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66be23ac",
        "outputId": "ad0f4b5d-3713-4729-e569-79f33c041003"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training model with fine-tuning...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 154MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (104688771 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (89747104 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.5781, Train Acc: 0.6986 | Val Loss: 0.5077, Val Acc: 0.7363\n",
            "Epoch 2/10 | Train Loss: 0.4358, Train Acc: 0.8019 | Val Loss: 0.4150, Val Acc: 0.8085\n",
            "Epoch 3/10 | Train Loss: 0.4020, Train Acc: 0.8141 | Val Loss: 0.3912, Val Acc: 0.8383\n",
            "Epoch 4/10 | Train Loss: 0.3792, Train Acc: 0.8332 | Val Loss: 0.3801, Val Acc: 0.8458\n",
            "Epoch 5/10 | Train Loss: 0.3562, Train Acc: 0.8475 | Val Loss: 0.3879, Val Acc: 0.8333\n",
            "Epoch 6/10 | Train Loss: 0.3601, Train Acc: 0.8448 | Val Loss: 0.3844, Val Acc: 0.8159\n",
            "Epoch 7/10 | Train Loss: 0.3223, Train Acc: 0.8713 | Val Loss: 0.3574, Val Acc: 0.8433\n",
            "Epoch 8/10 | Train Loss: 0.3437, Train Acc: 0.8432 | Val Loss: 0.3784, Val Acc: 0.8383\n",
            "Epoch 9/10 | Train Loss: 0.3394, Train Acc: 0.8586 | Val Loss: 0.3548, Val Acc: 0.8483\n",
            "Epoch 10/10 | Train Loss: 0.3298, Train Acc: 0.8522 | Val Loss: 0.3739, Val Acc: 0.8333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (96631920 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (94487082 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (101859328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fire       0.91      0.78      0.84       159\n",
            "      nofire       0.87      0.95      0.91       251\n",
            "\n",
            "    accuracy                           0.89       410\n",
            "   macro avg       0.89      0.87      0.88       410\n",
            "weighted avg       0.89      0.89      0.88       410\n",
            "\n",
            "Confusion Matrix:\n",
            "[[124  35]\n",
            " [ 12 239]]\n"
          ]
        }
      ],
      "source": [
        "# === Fine-tuning Pretrained Model ===\n",
        "print(\"\\nTraining model with fine-tuning...\")\n",
        "model = build_finetuned_model().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)  # Fine-tune only the last layer\n",
        "\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)\n",
        "evaluate_model(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "otSrqfk8MEQz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otSrqfk8MEQz",
        "outputId": "5231ff39-98d2-41f0-b060-2568870afcdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training model with fine-tuning...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (104688771 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 | Train Loss: 0.3200, Train Acc: 0.8533 | Val Loss: 0.2324, Val Acc: 0.9129\n",
            "Epoch 2/10 | Train Loss: 0.1992, Train Acc: 0.9237 | Val Loss: 0.2073, Val Acc: 0.9204\n",
            "Epoch 3/10 | Train Loss: 0.1834, Train Acc: 0.9269 | Val Loss: 0.2228, Val Acc: 0.9104\n",
            "Epoch 4/10 | Train Loss: 0.1531, Train Acc: 0.9439 | Val Loss: 0.2034, Val Acc: 0.9229\n",
            "Epoch 5/10 | Train Loss: 0.1404, Train Acc: 0.9476 | Val Loss: 0.1784, Val Acc: 0.9254\n",
            "Epoch 6/10 | Train Loss: 0.1422, Train Acc: 0.9449 | Val Loss: 0.1726, Val Acc: 0.9328\n",
            "Epoch 7/10 | Train Loss: 0.1266, Train Acc: 0.9497 | Val Loss: 0.1786, Val Acc: 0.9328\n",
            "Epoch 8/10 | Train Loss: 0.1221, Train Acc: 0.9507 | Val Loss: 0.1780, Val Acc: 0.9279\n",
            "Epoch 9/10 | Train Loss: 0.1209, Train Acc: 0.9534 | Val Loss: 0.1707, Val Acc: 0.9328\n",
            "Epoch 10/10 | Train Loss: 0.1183, Train Acc: 0.9566 | Val Loss: 0.1761, Val Acc: 0.9303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (96631920 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (94487082 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:3442: DecompressionBombWarning: Image size (101859328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fire       0.93      0.94      0.93       159\n",
            "      nofire       0.96      0.95      0.96       251\n",
            "\n",
            "    accuracy                           0.95       410\n",
            "   macro avg       0.94      0.94      0.94       410\n",
            "weighted avg       0.95      0.95      0.95       410\n",
            "\n",
            "Confusion Matrix:\n",
            "[[149  10]\n",
            " [ 12 239]]\n"
          ]
        }
      ],
      "source": [
        "# === Fine-tuning Video Transformer ===\n",
        "print(\"\\nTraining model with fine-tuning...\")\n",
        "model= ViT_model().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.head.parameters(), lr=learning_rate)\n",
        "\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)\n",
        "evaluate_model(model, test_loader)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
