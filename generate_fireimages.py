# -*- coding: utf-8 -*-
"""generate_fireImages.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KhTN00KWu5rHoChvBKuRRfgwOKyDaAt_
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import torch
from torchvision.utils import save_image
from diffusers import UNet2DModel, DDPMScheduler


# === Settings ===
model_path = "/content/drive/MyDrive/samples/model_epoch_450.pth"
output_dir = "/content/drive/MyDrive/generated_images/fire"
num_images = 420
batch_size = 10

os.makedirs(output_dir, exist_ok=True)

# === Load model ===
device = "cuda" if torch.cuda.is_available() else "cpu"

model = UNet2DModel(
    sample_size=128,
    in_channels=3,
    out_channels=3,
    layers_per_block=3,
    block_out_channels=(128, 128, 256, 256),
    down_block_types=("DownBlock2D",) * 4,
    up_block_types=("UpBlock2D",) * 4,
)
model.load_state_dict(torch.load(model_path, map_location=device))
model.to(device).eval()

# === Noise scheduler ===
noise_scheduler = DDPMScheduler(num_train_timesteps=1000)

# === Sampling loop ===
img_count = 0
while img_count < num_images:
    current_batch_size = min(batch_size, num_images - img_count)
    x = torch.randn((current_batch_size, 3, 128, 128), device=device)

    with torch.no_grad():
        for t in reversed(range(1000)):
            t_batch = torch.full((x.size(0),), t, device=device, dtype=torch.long)
            noise_pred = model(x, t_batch).sample
            x = noise_scheduler.step(noise_pred, t, x).prev_sample

    x = (x.clamp(-1, 1) + 1) / 2

    for i in range(x.size(0)):
        save_image(x[i], os.path.join(output_dir, f"gen_{img_count+60:03d}.png"))
        img_count += 1

print(f"{num_images} images saved to {output_dir}")