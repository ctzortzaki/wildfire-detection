# -*- coding: utf-8 -*-
"""ddpm-fire.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ftMRQ-yZnMXqZggzURJp5vXrriLOuN2l
"""

from google.colab import drive
drive.mount('/content/drive')

train_dir = '/content/drive/MyDrive/the_wildfire_dataset_2n_version/train/fire'

import os
import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import torchvision.utils as vutils
from diffusers import DDPMScheduler, UNet2DModel
from torchvision.models import inception_v3
import numpy as np
from scipy import linalg
from torchvision.datasets.folder import default_loader
from tqdm.auto import tqdm

# Save paths
save_dir = "/content/drive/MyDrive/"
samples_dir = os.path.join(save_dir, "samples")
os.makedirs(samples_dir, exist_ok=True)

class FireImageDataset(torch.utils.data.Dataset):
    def __init__(self, img_dir, transform=None):
        self.img_paths = [os.path.join(img_dir, f) for f in os.listdir(img_dir)
                          if f.endswith(('.jpg', '.png', '.jpeg'))]
        self.transform = transform

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        img = default_loader(self.img_paths[idx])
        if self.transform:
            img = self.transform(img)
        return img  # no label

# Transformations
transform = transforms.Compose([
    transforms.Resize(128),
    transforms.CenterCrop(128),
    transforms.ToTensor(),
    transforms.Normalize([0.5] * 3, [0.5] * 3)
])

# Dataset and DataLoader
# dataset = datasets.ImageFolder(root=train_dir, transform=transform)
dataset = FireImageDataset(train_dir, transform=transform)
dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=2)

# Define UNet model
model = UNet2DModel(
    sample_size=128,
    in_channels=3,
    out_channels=3,
    layers_per_block=3,
    block_out_channels=(128, 128, 256, 256),
    down_block_types=("DownBlock2D",) * 4,
    up_block_types=("UpBlock2D",) * 4,
)

# Noise scheduler & optimizer
noise_scheduler = DDPMScheduler(num_train_timesteps=1000)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# Device
device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)

inception = inception_v3(pretrained=True, transform_input=False).to(device).eval()

# Define transform for InceptionV3 (299x299 and unnormalized)
inception_transform = transforms.Compose([
    transforms.Resize((299, 299)),
    transforms.ToTensor()
])

# Load real fire images
real_dataset = FireImageDataset('/content/drive/MyDrive/the_wildfire_dataset_2n_version/train/fire', inception_transform)
real_loader = DataLoader(real_dataset, batch_size=32, shuffle=False)

def extract_features(dataloader):
    feats = []
    with torch.no_grad():
        for imgs in tqdm(dataloader, desc="Extracting Real Features"):
            imgs = imgs.cuda()
            feats.append(inception(imgs).cpu().numpy())
    return np.concatenate(feats, axis=0)

real_feats = extract_features(real_loader)
np.save("/content/drive/MyDrive/fire_real_features.npy", real_feats)

def calculate_fid(real_feats, fake_feats):
    mu1, sigma1 = real_feats.mean(axis=0), np.cov(real_feats, rowvar=False)
    mu2, sigma2 = fake_feats.mean(axis=0), np.cov(fake_feats, rowvar=False)

    diff = mu1 - mu2
    covmean, _ = linalg.sqrtm(sigma1 @ sigma2, disp=False)

    if np.iscomplexobj(covmean):
        covmean = covmean.real

    fid = diff.dot(diff) + np.trace(sigma1 + sigma2 - 2 * covmean)
    return fid

# # --- Resume logic ---
# checkpoint_path = os.path.join(samples_dir, "model_epoch_150.pth")
# if os.path.exists(checkpoint_path):
#     print(f"Resuming from checkpoint: {checkpoint_path}")
#     model.load_state_dict(torch.load(checkpoint_path, map_location=device))
#     # Optional: If you saved optimizer state, load it too
#     # optimizer.load_state_dict(torch.load(os.path.join(samples_dir, "optimizer_epoch_050.pth")))
#     start_epoch = 151
#     # if os.path.exists(os.path.join(save_dir, "losses.npy")):
#     #   losses = list(np.load(os.path.join(save_dir, "losses.npy")).tolist())
#     # else:
#     #   start_epoch = 0
#     #   losses = []

start_epoch = 0
losses = []
fid_scores = []

# Training loop
num_epochs = 501
for epoch in range(start_epoch, num_epochs):
    model.train()

    epoch_loss = 0.0

    scaler = torch.cuda.amp.GradScaler()

    for batch in dataloader:
        clean_images = batch.to(device)

        noise = torch.randn_like(clean_images)
        timesteps = torch.randint(0, 1000, (clean_images.shape[0],), device=device).long()
        noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)

        optimizer.zero_grad()

        with torch.cuda.amp.autocast():
            noise_pred = model(noisy_images, timesteps).sample
            loss = torch.nn.functional.mse_loss(noise_pred, noise)

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        epoch_loss += loss.item()


    print(f"Epoch {epoch}, Loss: {loss.item()}")
    epoch_loss /= len(dataloader)
    print(f"Epoch {epoch}, Avg Loss: {epoch_loss:.4f}")
    losses.append(epoch_loss)
    np.save(os.path.join(save_dir, "losses.npy"), np.array(losses))


    # === Save & generate samples every 10 epochs and at last epoch ===
    if epoch % 10 == 0 or epoch == num_epochs - 1:
        model.eval()
        with torch.no_grad():
            x = torch.randn((32, 3, 128, 128)).to(device)
            for t in reversed(range(1000)):
                t_batch = torch.full((x.size(0),), t, device=device, dtype=torch.long)
                noise_pred = model(x, t_batch).sample
                x = noise_scheduler.step(noise_pred, t, x).prev_sample

            samples = (x.clamp(-1, 1) + 1) / 2
            grid = vutils.make_grid(samples.cpu(), nrow=4)

            plt.figure(figsize=(6, 6))
            plt.axis("off")
            plt.title(f"Samples at Epoch {epoch}")
            plt.imshow(grid.permute(1, 2, 0).numpy())
            plt.savefig(os.path.join(samples_dir, f"epoch_{epoch:03d}.png"))
            plt.close()

            # === Save model checkpoint every 10 epochs ===
            checkpoint_path = os.path.join(samples_dir, f"model_epoch_{epoch:03d}.pth")
            torch.save(model.state_dict(), checkpoint_path)
            print(f"Model checkpoint saved at: {checkpoint_path}")

            # Preprocess generated samples for Inception
            samples_resized = torch.nn.functional.interpolate(samples, size=(299, 299), mode='bilinear', align_corners=False)
            samples_resized = samples_resized.to(device)

            with torch.no_grad():
                gen_feats = inception(samples_resized).cpu().numpy()

            # Load saved real features
            real_feats = np.load("/content/drive/MyDrive/fire_real_features.npy")
            fid = calculate_fid(real_feats, gen_feats)
            print(f"Epoch {epoch} FID: {fid}")

            # Optionally save to a list or log
            fid_scores.append(fid)
            np.save(os.path.join(save_dir, "fid_scores.npy"), np.array(fid_scores))
